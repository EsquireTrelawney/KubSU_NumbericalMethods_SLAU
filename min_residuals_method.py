import numpy as np


# Решение методом минимальных невязок
# НА вход подаются матрица коэффициентов и столбец свободных коэфф, а так же точность(по умолчанию 0,00001
def minimal_residuals_solve(A, b, x, eps=1.0e-5, max_iter = 1000):
    num_iterations = 0 # Считаем итерации
    #x = np.zeros_like(b)  # это включать для решения 11ого задания. Там можно и нулевой брать вектор за начальный
    # x = np.array([100, 200, 90]) # Вектор приближенных решений. Для начала это просто нуль-вектор того же размера, что и b
                                 # НО ДЛЯ ТРЕТЬЕГО ЗАДАНИЯ ЛУЧШЕ ВЗЯТЬ ВЕКТОР ПОБЛИЖЕ К НАСТОЯЩЕМУ РЕШЕНИЮ

   # Итерации происходят, пока норма вектора невязки больше заданной точности
    while np.linalg.norm(np.dot(A, x) - b) > eps and num_iterations < max_iter:
        num_iterations += 1
        r = np.dot(A, x) - b  # высчитываем направление невязки (вектор), которые представляет разницу между текущим
                              # приближением Ax и вектором свободных коэфф
        # высчитываем коэф. поправки вектора невязки путём деления скалярного произведения матрицы и вектора невязки на
        # квадрат нормы вектора невязки
        t = np.dot((np.dot(A, r)).transpose(), r) / (np.linalg.norm(np.dot(A, r))**2)
        # Корректируем вектор решения, вычитая из текущего приближения коэффициент t, умноженный на вектор невязки
        x = x - float(t) * r

    return x, num_iterations # возвращаем вектор решений и кол-во итераций

